<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Archives: 2014 | Alpha&#39;s Blog</title>
  <meta name="author" content="Wenqiang.Xu">
  
  <meta name="description" content="Natural Language Processing | Mechine Learning | Pattern Recognition | Language Model | Deep Learning | Recurrent Neutral Network | Speech Recognition">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Alpha&#39;s Blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Alpha&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8/jquery.min.js"></script>
  
</head>

<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Alpha&#39;s Blog</a></h1>
  <h2><a href="/">Try to Understand, Try to Conquer</a></h2>
</div>
<nav id="main-nav">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">About</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
<div class="alignleft" style="margin-top: 15px">


</div>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="wrapper">
<h2 class="archive-title">2014</h2>


  
    <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
  
    <h1 class="title"><a href="/2014/11/07/Rnn-Language-Model/">Rnn Language Model</a></h1>
  

      
        <p class="published">
          Published: <time datetime="2014-11-07T09:38:01.000Z">11月 7 2014</time>
        </p>
      
    </header>
    <div class="entry">
      
        
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- hackish -->

  
    <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
  
    <h1 class="title"><a href="/2014/11/07/N-Gram-Language-Model/">N-Gram Language Model</a></h1>
  

      
        <p class="published">
          Published: <time datetime="2014-11-07T09:37:48.000Z">11月 7 2014</time>
        </p>
      
    </header>
    <div class="entry">
      
        
      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- hackish -->

  
    <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
  
    <h1 class="title"><a href="/2014/11/07/New-Word-Extraction/">New Word Extraction</a></h1>
  

      
        <p class="published">
          Published: <time datetime="2014-11-07T09:35:08.000Z">11月 7 2014</time>
        </p>
      
    </header>
    <div class="entry">
      
        <h2 id="Introduction">Introduction</h2>
<p>As we all know, vocabulary plays an important role in speech recognition, machine translation, natural language understanding and other NLP jobs. So efficiently automatic new word extraction from large scale corpus can release manual burden dramatically. In my experience, most e-commerce company emphasize new word collection, because those new words will be regarded as features and do help in their subsequent analytic jobs.</p>
<p>The main idea of this blog comes from one article from web, which you can refer to <a href="http://www.matrix67.com/blog/archives/5044" target="_blank" rel="external">here</a>. After reading, I find the idea proposed is so cool and amazing, so I decide to implement it. By coincidence I have just buit our language model trainning framework on hadoop platform at that time, and hadoop become my choice naturally. This is the first time I get a taste of the charm of data minning. Thanks to Matrix67.</p>
<h2 id="Main_Idea">Main Idea</h2>
<p>Befor we step into details, We should think over a question first, namely, how a word can be a real word? This question is quite weird, isn’t it? But different answers to it generate totally different way of processing. In Matrix67’s article, he mainly mantains two points. First, those words before and behind this candidate word should be as more diverse as possible. Second, the inner coherence of this word also need to be as strong as possible.</p>
<p>As for the first point above, that is to say we hope few words can cooperate with the candidate word to make a fixed combination. And it is natural to use entropy to measure the diversity around a candidate word. For the second point, the candidate word is probably made by several sub words in return, so we do hope the probablity of this word higher than those sub words appear independently in corpus. This time we can use a simple ralative entropy form to decide the similarity of word distribution.</p>
<p>May be here you still can not believe that such simple idea can leads to admiring results, but it does.</p>
<h2 id="Roadblocks">Roadblocks</h2>
<p>It’s not difficult to compute entropy around a candidate word thinking in mapreduce. Here suppose you’v already known some basic knowledge about hadoop, like hdfs, mapreduce and so on. To compute entropy around a candidate word, we need to have several steps as follow.</p>
<p>First, split corpus lines into a large amount of candidate words using suffix representation; </p>
<p>Second, compute word frequency when we have got the result from last step;</p>
<p>Third, find out all words around a candidate word and count their occurence each, then compute its left and right entropy respectively. No doult, this step should go through all candidate words;</p>
<p>Last, entropy threshold need to be set, in my experiment, it’s 1.5. If the left and right entropy of a candidate word all greater than this threshold value, then this word will be passed to next stage filtering.</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- hackish -->

  
    <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
  
    <h1 class="title"><a href="/2014/11/07/My-First-Post/">My First Hexo Journey</a></h1>
  

      
        <p class="published">
          Published: <time datetime="2014-11-07T02:03:20.000Z">11月 7 2014</time>
        </p>
      
    </header>
    <div class="entry">
      
        <h2 id="Welcome_to_My_Hexo_Blog_Zone!">Welcome to My Hexo Blog Zone!</h2>
<p>So excited to share life things with you guys here. To celebrate my first vergin journey, I would like to write some words down below.</p>
<p>I always wish to find one cool place to record the little drops of my life, but never succeed until several days before when I suddenly met hexo developed by a student in Taiwan. Hexo is a kind of static web page generator, and by which we can build our own personal blog on our local machine, then move it over to github. Unlike common blog systems, web pages generated by hexo is very clean and tidy, no ad and other annoying things, and also the blog theme can be customized. So cool and I really love it, thanks a lot to the author. If you want to know more about hexo, you can click <a href="http://hexo.io" target="_blank" rel="external">here</a>.</p>
<p>Ha, Let’s start our hexo blog journey now. But first we need get familiar to hexo grammar.</p>

      
    </div>
    <footer>
      
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>
<!-- hackish -->

  

  <nav id="pagination">
  
  
  <div class="clearfix"></div>
</nav>
</div>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2014 Wenqiang.Xu
  
</div>
<div class="clearfix"></div></footer>
  <script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>